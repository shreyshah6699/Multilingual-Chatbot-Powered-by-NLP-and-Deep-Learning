{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c80a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('chatbot_intents_dataset_from_json.csv')  # Replace with the path to the downloaded dataset\n",
    "\n",
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "\n",
    "# Helper functions for preprocessing\n",
    "def tokenize(sentence):\n",
    "    return sentence.split()\n",
    "\n",
    "def stem(word):\n",
    "    stemmer = PorterStemmer()\n",
    "    return stemmer.stem(word.lower())\n",
    "\n",
    "def bag_of_words(tokenized_sentence, words):\n",
    "    sentence_words = [stem(w) for w in tokenized_sentence]\n",
    "    bag = np.zeros(len(words), dtype=np.float32)\n",
    "    for idx, w in enumerate(words):\n",
    "        if w in sentence_words:\n",
    "            bag[idx] = 1\n",
    "    return bag\n",
    "\n",
    "# Process each pattern in the dataset\n",
    "ignore_words = ['?', '!', '.', ',']\n",
    "for _, row in df.iterrows():\n",
    "    tag = row['Tag']\n",
    "    pattern = row['Pattern']\n",
    "    w = tokenize(pattern)\n",
    "    all_words.extend(w)\n",
    "    xy.append((w, tag))\n",
    "    if tag not in tags:\n",
    "        tags.append(tag)\n",
    "\n",
    "# Filter out unwanted characters and stem words\n",
    "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))\n",
    "\n",
    "# Create training data\n",
    "X_train = []\n",
    "y_train = []\n",
    "for (pattern_sentence, tag) in xy:\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    X_train.append(bag)\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91f0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        return out\n",
    "\n",
    "class ChatDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = y_train\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf5a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "FILE = \"trained_chat_model.pth\"\n",
    "\n",
    "# Check if the file exists in the current directory\n",
    "if not os.path.exists(FILE):\n",
    "    # Hyper-parameters\n",
    "    batch_size = 8\n",
    "    hidden_size = 8\n",
    "    output_size = len(tags)\n",
    "    input_size = len(X_train[0])\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 500\n",
    "\n",
    "    # Data loader\n",
    "    train_loader = DataLoader(dataset=ChatDataset(), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Model initialization\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        for (words, labels) in train_loader:\n",
    "            words = words.to(device)\n",
    "            labels = labels.to(dtype=torch.long).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(words)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    data = {\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"input_size\": input_size,\n",
    "        \"hidden_size\": hidden_size,\n",
    "        \"output_size\": output_size,\n",
    "        \"all_words\": all_words,\n",
    "        \"tags\": tags\n",
    "    }\n",
    "\n",
    "    torch.save(data, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39e2820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (l1): Linear(in_features=125, out_features=8, bias=True)\n",
       "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (l3): Linear(in_features=8, out_features=11, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model(model_file):\n",
    "    data = torch.load(model_file)\n",
    "    model_state = data[\"model_state\"]\n",
    "    input_size = data[\"input_size\"]\n",
    "    hidden_size = data[\"hidden_size\"]\n",
    "    output_size = data[\"output_size\"]\n",
    "    all_words = data[\"all_words\"]\n",
    "    tags = data[\"tags\"]\n",
    "\n",
    "    model = NeuralNet(input_size, hidden_size, output_size)\n",
    "    model.load_state_dict(model_state)\n",
    "    model.eval()\n",
    "\n",
    "    return model, all_words, tags\n",
    "\n",
    "def predict(model, sentence, all_words, tags, device):\n",
    "    model.to(device)\n",
    "    sentence = tokenize(sentence)\n",
    "    X = bag_of_words(sentence, all_words)\n",
    "    X = torch.from_numpy(X).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(X)\n",
    "        _, predicted = torch.max(output, dim=1)\n",
    "        tag = tags[predicted.item()]\n",
    "\n",
    "    return tag\n",
    "\n",
    "# Load the model and make a prediction\n",
    "model, all_words, tags = load_model(FILE)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5d9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load and parse the JSON file\n",
    "with open('intents_en.json', 'r') as file:\n",
    "    intents_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05205bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_response(tag):\n",
    "    for intent in intents_json['intents']:\n",
    "        if tag == intent['tag']:\n",
    "            return random.choice(intent['responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cc2ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weather import get_weather\n",
    "from joke import get_joke\n",
    "from dictionary import get_meaning\n",
    "from horoscope import get_horoscope\n",
    "from translation import translate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df951503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Input Language: en\n",
      "Enter Reply Language: hi\n",
      "You: horoscope\n",
      "Predicted tag: horoscope\n",
      "Enter Sun Sign: cancer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: line 1: google-chrome: command not found\n",
      "/bin/sh: line 1: google-chrome: command not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "एक बहुत ही महत्वपूर्ण तत्व आपके दिन से गायब है, और आपको यह सुनिश्चित करने की जरूरत है कि आप इसे दिन के अंत से पहले ढूंढते हैं. क्या आपने मेहमानों की सूची से एक मजेदार व्यक्ति छोड़ दिया है? स्कूल में अपने काम को डबल-चिकन करने के लिए भूल गए हैं? आपको धीमा करने और चीजों के माध्यम से सोचने की जरूरत है ताकि आप खुद को याद कर सकें कि आप भूल गए हैं. आप के साथ शिकार पर एक दोस्त प्राप्त करें. उनसे पूछें कि क्या वे जानते हैं कि आप क्या याद करने की कोशिश कर रहे हैं. अगर वे नहीं करते हैं, तो वे आपकी स्मृति में योग करने में मदद कर सकते हैं.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m tgt_lang \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter Reply Language: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     tag \u001b[38;5;241m=\u001b[39m predict(model, sentence, all_words, tags, device)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted tag: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.11/site-packages/ipykernel/kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1200\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1206\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1207\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/torch/lib/python3.11/site-packages/ipykernel/kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Chatbot interaction\n",
    "src_lang = input(\"Enter Input Language: \")\n",
    "tgt_lang = input(\"Enter Reply Language: \")\n",
    "\n",
    "while True:\n",
    "    sentence = input(\"You: \")\n",
    "    tag = predict(model, sentence, all_words, tags, device)\n",
    "    print(f\"Predicted tag: {tag}\")\n",
    "    if tag == \"joke\":\n",
    "        print(f\"{translate_text(get_joke(), src_lang, tgt_lang)}\")\n",
    "    elif tag == \"weather\":\n",
    "        print(f\"{translate_text(get_weather(), src_lang, tgt_lang)}F\")\n",
    "    elif tag == \"horoscope\":\n",
    "        print(f\"{translate_text(get_horoscope(), src_lang, tgt_lang)}\")\n",
    "    elif tag == \"dictionary\":\n",
    "        print(f\"{translate_text(get_meaning(), src_lang, tgt_lang)}\")\n",
    "    elif tag == \"sudoku\":\n",
    "        ## TO DO\n",
    "        print(\"Sudoku\")\n",
    "    elif tag == \"goodbye\":\n",
    "        response = get_response(tag)\n",
    "        print(f\"Chatbot: {translate_text(response, src_lang, tgt_lang)}\")\n",
    "        break\n",
    "    else:\n",
    "        response = get_response(tag)\n",
    "        print(f\"Chatbot: {translate_text(response, src_lang, tgt_lang)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b32765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
